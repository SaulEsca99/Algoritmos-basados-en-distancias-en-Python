# üìä Actividad 1: Algoritmos basados en distancias en Python  
## MACHINE LEARNING

**Integrantes:**
* Gonz√°lez P√©rez Monserrat  
* Escamilla Lazcano Sa√∫l  
* P√©rez M√©ndez Nancy Esmeralda  
* Valencia Hernandez Kevin Guadalupe  
* Zamudio L√≥pez Leonardo  

**Grupo:** 5BV1  
**Profesora:** Dra. Camacho V√°zquez Vanessa Alejandra  
**Fecha:** 03/09/25  

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Pandas](https://img.shields.io/badge/Pandas-Data%20Analysis-green.svg)](https://pandas.pydata.org/)
[![NumPy](https://img.shields.io/badge/NumPy-Arrays-orange.svg)](https://numpy.org/)

---

## üöÄ Descripci√≥n general del proyecto

Este repositorio contiene la implementaci√≥n en Python de algoritmos de clasificaci√≥n **basados en distancias**, principalmente:

- **K-Nearest Neighbors (K-NN)**
- **Clasificador de M√≠nima Distancia (basado en centroides)**

Adem√°s, se incluyen:

- Utilidades para **carga y preprocesamiento b√°sico de datos** desde archivos de texto/CSV.
- Implementaci√≥n de **m√©todos de validaci√≥n** para evaluar el desempe√±o de los clasificadores:
  - Train/Test
  - K-Fold Cross Validation
  - Bootstrap

El c√≥digo est√° orientado a ser **interactivo en consola**, permitiendo al usuario:
1. Cargar diferentes archivos de datos.
2. Seleccionar qu√© columnas ser√°n **features (entrada)** y cu√°l ser√° la **clase (salida)**.
3. Probar clasificadores con puntos ingresados manualmente.
4. Evaluar el rendimiento de los algoritmos con distintos m√©todos de validaci√≥n.

---

## üóÇÔ∏è Estructura del repositorio

- `AlgoritmosBasadosEnDistancias.py`  
  Programa principal para:
  - Cargar datos desde CSV.
  - Seleccionar columnas de entrada/salida.
  - Calcular centroides.
  - Clasificar puntos nuevos con:
    - M√≠nima Distancia (centroides)
    - K-NN (con K configurable)
  - Mostrar estad√≠sticas descriptivas b√°sicas.

- `MetodosValidacion.py`  
  Implementa los m√©todos de validaci√≥n:
  - **Train/Test**
  - **K-Fold Cross Validation**
  - **Bootstrap**
  
  Todo utilizando como clasificadores:
  - M√≠nima Distancia
  - K-NN

- `CargaDatos.py`  
  M√≥dulo general para:
  - Cargar archivos de texto separados por un delimitador.
  - Determinar el **tipo de dato** de cada columna (entero, flotante, booleano, cadena).
  - Determinar el **tipo de medida** (discreta, continua, nominal).
  - Seleccionar subconjuntos de **atributos** (columnas) y **renglones** (filas).
  - Guardar matrices reducidas en nuevos archivos.

- Conjuntos de datos de ejemplo (formato texto/CSV):
  - `iris.data`
  - `zoo.data`
  - `wine.data`

---

## üßÆ 1. Algoritmos basados en distancias

El n√∫cleo del proyecto es la implementaci√≥n de clasificadores que deciden la clase de un patr√≥n nuevo a partir de **distancias** en el espacio de caracter√≠sticas.

### üîπ Distancias implementadas

En `AlgoritmosBasadosEnDistancias.py` se utilizan principalmente:

- **Distancia euclidiana**  
  \[
  d(\mathbf{x}, \mathbf{y}) = \sqrt{\sum_{i}(x_i - y_i)^2}
  \]

- **Distancia Manhattan** (solo en el m√≥dulo interactivo de clasificaci√≥n)  
  \[
  d(\mathbf{x}, \mathbf{y}) = \sum_{i}|x_i - y_i|
  \]

Estas funciones reciben dos vectores num√©ricos (lista o arreglo de NumPy) y devuelven la distancia entre ellos.

---

## üß± 2. Clasificador de M√≠nima Distancia (Centroides)

En este m√©todo:

1. Para cada clase se calcula su **centroide**:
   - Es el **promedio** de todos los vectores de entrenamiento pertenecientes a esa clase.
2. Para un nuevo punto a clasificar:
   - Se calcula la distancia a cada centroide.
   - Se asigna la clase del centroide **m√°s cercano**.

El m√≥dulo:
- Calcula y muestra para cada clase:
  - N√∫mero de patrones.
  - Centroide correspondiente.
- Permite elegir la m√©trica de distancia:
  - Euclidiana.
  - Manhattan (en modo interactivo).

---

## üîÑ 3. Clasificador K-Nearest Neighbors (K-NN)

K-NN es un clasificador **no param√©trico** que funciona as√≠:

1. Dado un punto nuevo, calcula la distancia a **todos** los puntos de entrenamiento.
2. Ordena las distancias de menor a mayor.
3. Toma los **K vecinos m√°s cercanos**.
4. La clase predicha es la **m√°s frecuente** entre esos K vecinos (votaci√≥n mayoritaria).

En el c√≥digo se permite:
- Configurar el valor de **K** (si no es v√°lido, se usa K = 3 por defecto).
- Elegir el tipo de distancia (euclidiana o manhattan, seg√∫n el m√≥dulo).

El programa tambi√©n imprime, a modo de depuraci√≥n:
- Algunas de las primeras distancias calculadas.
- Los K vecinos m√°s cercanos:
  - √çndice en el conjunto de entrenamiento.
  - Clase.
  - Distancia.

---

## üìä 4. M√©todos de validaci√≥n implementados

En `MetodosValidacion.py` se incluyen varias estrategias para estimar el rendimiento de los clasificadores:

### 4.1 Train/Test

- Se divide el conjunto de datos en:
  - **Entrenamiento**: porcentaje configurable (ej. 70%).
  - **Prueba**: el resto (ej. 30%).
- Se entrena el clasificador con el conjunto de entrenamiento.
- Se prueba en el conjunto de prueba.
- Se calculan:
  - Porcentaje de **eficiencia (accuracy)**.
  - Porcentaje de **error**.
  - N√∫mero de patrones correctamente clasificados.

### 4.2 K-Fold Cross Validation

- Se elige un n√∫mero **K** de folds (por defecto 5).
- Se barajan los datos y se repite:
  - Para cada fold:
    - Ese fold se usa como **prueba**.
    - Los dem√°s folds se usan como **entrenamiento**.
- Se promedian:
  - Eficiencia.
  - Error.
  - Se calcula tambi√©n la **desviaci√≥n est√°ndar** de ambas m√©tricas.

### 4.3 Bootstrap

- Se repiten **K experimentos** (configurable, por defecto 10).
- En cada experimento:
  - Conjunto de aprendizaje: muestreo **con reemplazo**.
  - Conjunto de prueba: muestreo **sin reemplazo**.
- Se calcula:
  - Eficiencia y error globales por experimento.
  - Eficiencia y error **por clase**, con promedio y desviaci√≥n est√°ndar.

---

## üì• 5. Carga y an√°lisis b√°sico de datos

### 5.1 Desde CSV (Pandas)

Tanto `AlgoritmosBasadosEnDistancias.py` como `MetodosValidacion.py`:

- Preguntan si el archivo tiene **encabezados** (nombres de columnas).
- Cargan el archivo con `pandas.read_csv`.
- Muestran:
  - Dimensiones del dataset.
  - Nombres de columnas.
  - Primeras filas.
- Permiten elegir por teclado:
  - Columnas de **entrada (features)**.
  - Columna de **salida (clase)**.

### 5.2 Desde archivo de texto gen√©rico

`CargaDatos.py`:

- Pide:
  - Ruta del archivo.
  - Delimitador (por ejemplo `,` o `;`).
- Construye una **matriz** (lista de listas) con todos los valores.
- Determina:
  - Tipo de dato predominante por columna (entero, flotante, booleano, cadena).
  - Tipo de medida (discreta, continua, nominal).
- Permite:
  - Seleccionar subconjuntos de **atributos**.
  - Seleccionar subconjuntos de **renglones**.
  - Guardar matrices reducidas en nuevos archivos.

---

## üß™ 6. Conjuntos de datos de ejemplo

En el repositorio se incluyen archivos cl√°sicos de aprendizaje de m√°quina (formato texto/CSV):

- `iris.data` ‚Äì Conjunto de datos de flores Iris.
- `zoo.data` ‚Äì Conjunto de datos de animales con atributos booleanos/categ√≥ricos.
- `wine.data` ‚Äì Conjunto de datos de vinos con atributos num√©ricos.

Estos archivos se pueden usar tanto para:
- Probar los **clasificadores basados en distancias**.
- Probar los **m√©todos de validaci√≥n**.

---

## üõ†Ô∏è 7. Requisitos

- **Python** 3.10.19
- Librer√≠as de Python:
  - `pandas`
  - `numpy`
  - `math` (est√°ndar)
  - `collections` (est√°ndar)
  - `random` (est√°ndar)

